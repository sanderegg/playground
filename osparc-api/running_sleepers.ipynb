{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_URL = \"https://api.osparc\"\n",
    "WEB_API_URL = \"https://osparc\"\n",
    "USERNAME = \"THEUSER\"\n",
    "PASSWORD = \"THEPASSWORD\"\n",
    "API_KEY = \"b02ee1b0-b089-59f0-bd14-44919b2fa165\"\n",
    "API_SECRET = \"2cf84558-d757-5a1b-a351-1c81b5f2d93d\"\n",
    "SOLVER_NAME = \"simcore/services/comp/itis/sleeper\"\n",
    "SOLVER_VERSION = \"2.1.6\"\n",
    "\n",
    "CLUSTER_ID = 0 # run on the default cluster\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# initialize connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing.pool import AsyncResult\n",
    "from tenacity import AsyncRetrying, TryAgain, retry_if_exception_type\n",
    "from tenacity.wait import wait_fixed\n",
    "from tqdm.notebook import tqdm\n",
    "import asyncio\n",
    "import functools\n",
    "import json\n",
    "import osparc\n",
    "import typing\n",
    "import urllib3\n",
    "\n",
    "\n",
    "cfg = osparc.Configuration(\n",
    "    host=f\"{API_URL}\",\n",
    "    username=API_KEY,\n",
    "    password=API_SECRET,\n",
    ")\n",
    "# cfg.debug = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with osparc.ApiClient(cfg) as api_client:\n",
    "    profile = osparc.UsersApi(api_client).get_my_profile()\n",
    "    solvers_api = osparc.SolversApi(api_client)\n",
    "    original_api_client_call_api = solvers_api.api_client.call_api\n",
    "\n",
    "    def patched_api_client_for_starting_jobs(*args, **kwargs):\n",
    "        # print(\"called with: \", args, kwargs)\n",
    "        if args[0] == \"/v0/solvers/{solver_key}/releases/{version}/jobs/{job_id}:start\" and args[1] == \"POST\":\n",
    "            query_params = args[3]\n",
    "            # print(\"called to start a job, let's add \", CLUSTER_ID, \"to\", query_params)\n",
    "            query_params.append((\"cluster_id\", CLUSTER_ID))\n",
    "            # print(\"changed to: \", args, kwargs)\n",
    "        return original_api_client_call_api(*args, **kwargs)\n",
    "\n",
    "    solvers_api.api_client.call_api = patched_api_client_for_starting_jobs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = typing.cast(osparc.Solver, solvers_api.get_solver_release(SOLVER_NAME, SOLVER_VERSION))\n",
    "print(solver)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def create_job(solver: osparc.Solver) -> osparc.Job:\n",
    "    result = await asyncio.get_running_loop().run_in_executor(None, functools.partial(solvers_api.create_job,\n",
    "            solver.id,\n",
    "            solver.version,\n",
    "            osparc.JobInputs(\n",
    "                {\n",
    "                    \"input_2\": 15,\n",
    "                    \"input_4\": 0\n",
    "                }\n",
    "            ), async_req=True\n",
    "        ))\n",
    "    assert isinstance(result, AsyncResult) # nosec\n",
    "    # print(job)\n",
    "    return typing.cast(osparc.Job, await asyncio.get_running_loop().run_in_executor(None, result.get))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# list jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def list_jobs(solver: osparc.Solver) -> list[osparc.Job]:\n",
    "    result = await asyncio.get_running_loop().run_in_executor(None, functools.partial(solvers_api.list_jobs, solver.id, solver.version, async_req=True))\n",
    "    assert isinstance(result, AsyncResult) # nosec\n",
    "    # print([job.id for job in jobs])\n",
    "    return typing.cast(list[osparc.Job], await asyncio.get_running_loop().run_in_executor(None, result.get))\n",
    "jobs =await list_jobs(solver)\n",
    "assert len(jobs) == 0, f\"found {len(jobs)} jobs\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inspect job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def inspect_job(solver: osparc.Solver, job: osparc.Job)-> osparc.JobStatus:\n",
    "    result = await asyncio.get_running_loop().run_in_executor(None, functools.partial(solvers_api.inspect_job, solver.id, solver.version, job.id,async_req=True))\n",
    "    assert isinstance(result, AsyncResult) # nosec\n",
    "    # print(status)\n",
    "    return typing.cast(osparc.JobStatus, await asyncio.get_running_loop().run_in_executor(None, result.get))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get job result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_job_result(solver: osparc.Solver, job: osparc.Job) -> osparc.JobOutputs:\n",
    "    result = await asyncio.get_running_loop().run_in_executor(None, functools.partial(solvers_api.get_job_outputs, solver.id, solver.version, job.id, async_req=True))\n",
    "    assert isinstance(result, AsyncResult) # nosecregistry.staging.osparc.io/simcore/services/comp/itis/sleeper:2.0.2\n",
    "    return typing.cast(osparc.JobOutputs, await asyncio.get_running_loop().run_in_executor(None, result.get))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# start job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def start_job(solver: osparc.Solver, job: osparc.Job) -> osparc.JobStatus:\n",
    "    result=  await asyncio.get_running_loop().run_in_executor(None, functools.partial(solvers_api.start_job, solver.id, solver.version, job.id,async_req=True))\n",
    "    assert isinstance(result, AsyncResult) # nosec\n",
    "    return typing.cast(osparc.JobStatus, await asyncio.get_running_loop().run_in_executor(None, result.get))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# delete a job corresponding project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _login_webserver() -> dict[str, str]:\n",
    "   # create a PoolManager instance\n",
    "    http = urllib3.PoolManager()\n",
    "\n",
    "    # define the URL of the login page\n",
    "    url = f'{WEB_API_URL}/v0/auth/login'\n",
    "\n",
    "    # define the data to be sent with the POST request\n",
    "    data = {'email': USERNAME, 'password': PASSWORD}\n",
    "\n",
    "    # send the POST request to the login page\n",
    "    response = http.request('POST', url, body=json.dumps(data), headers={'Content-Type': 'application/json'})\n",
    "\n",
    "    # print the response status code and content\n",
    "    if response.status != 200:\n",
    "        raise RuntimeError(\"failed to login!\")\n",
    "    \n",
    "    # get the cookies\n",
    "    cookies = response.headers.get(\"Set-Cookie\")\n",
    "    return cookies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_jobs(jobs: list[osparc.Job]) -> None:\n",
    "    # create a PoolManager instance\n",
    "    http = urllib3.PoolManager()\n",
    "\n",
    "    # define the URL of the login page\n",
    "    url = f'{WEB_API_URL}/v0/auth/login'\n",
    "\n",
    "    # define the data to be sent with the POST request\n",
    "    data = {'email': USERNAME, 'password': PASSWORD}\n",
    "\n",
    "    # send the POST request to the login page\n",
    "    response = http.request('POST', url, body=json.dumps( data), headers={'Content-Type': 'application/json'})\n",
    "\n",
    "    # print the response status code and content\n",
    "    if response.status != 200:\n",
    "        raise RuntimeError(\"failed to login!\")\n",
    "    # print(\"logged in, proceeding with deletion...\")\n",
    "\n",
    "    # get the cookies\n",
    "    cookies = response.headers.get(\"Set-Cookie\")\n",
    "\n",
    "    # delete a project\n",
    "    for job in tqdm(jobs, desc=\"Deleting jobs\"):\n",
    "        url = f'{WEB_API_URL}/v0/projects/{job.id}'\n",
    "        response = http.request(\"DELETE\", url, headers={'Content-Type': 'application/json', \"Cookie\": cookies})\n",
    "        # print(f\"job {job.id} is {'deleted' if response.status == 204 else 'failed to delete'}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### list jobs through webserver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "def list_job_ids_from_web_server() -> list[str]:\n",
    "    cookies = _login_webserver()\n",
    "    # create a PoolManager instance\n",
    "    http = urllib3.PoolManager()\n",
    "\n",
    "    # list projects that are hidden\n",
    "    url = f'{WEB_API_URL}/v0/projects?type=user&show_hidden=true'\n",
    "    offset = 0\n",
    "    limit = 30\n",
    "    response = http.request(\"GET\", f\"{url}&limit={limit}&offset={offset}\", headers={'Content-Type': 'application/json', \"Cookie\": cookies})\n",
    "    if response.status != 200:\n",
    "        raise RuntimeError(f\"Unable to list projects from webserver: {response.data}\")\n",
    "    data = json.loads(response.data)\n",
    "\n",
    "    total = data[\"_meta\"][\"total\"]\n",
    "    total_count = data[\"_meta\"][\"count\"]\n",
    "    offset += data[\"_meta\"][\"count\"]\n",
    "    list_of_job_ids = [project[\"uuid\"] for project in data[\"data\"] if str(project[\"name\"]).startswith(\"solvers/simcore\")]\n",
    "\n",
    "    while total_count < total:\n",
    "        response = http.request(\"GET\", f\"{url}&limit={limit}&offset={offset}\", headers={'Content-Type': 'application/json', \"Cookie\": cookies})\n",
    "        if response.status != 200:\n",
    "            raise RuntimeError(f\"Unable to list projects from webserver: {response.data}\")\n",
    "        data = json.loads(response.data)\n",
    "        list_of_job_ids += [project[\"uuid\"] for project in data[\"data\"] if str(project[\"name\"]).startswith(\"solvers/simcore\")]\n",
    "        total_count += data[\"_meta\"][\"count\"]\n",
    "        offset+=data[\"_meta\"][\"count\"]\n",
    "    \n",
    "    return list_of_job_ids\n",
    "\n",
    "list_of_job_ids = list_job_ids_from_web_server()\n",
    "print(len(list_of_job_ids))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fake jobs to delete them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = [osparc.Job(id=job_id, name=\"fake\", inputs_checksum=\"\", created_at=\"\", runner_name=\"blah\", url=\"asd\", runner_url=\"asd\", outputs_url=\"asd\") for job_id in list_of_job_ids]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run N sleepers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_JOBS = 20\n",
    "\n",
    "jobs = []\n",
    "with tqdm(total=NUM_JOBS, desc=\"Creating jobs\") as pbar:\n",
    "    for result in asyncio.as_completed([create_job(solver) for _ in range(NUM_JOBS)]):\n",
    "        job = await result\n",
    "        jobs.append(job)\n",
    "        pbar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_job(solver: osparc.Solver, job: osparc.Job):\n",
    "    with tqdm(total=100) as pbar:\n",
    "        await start_job(solver, job)\n",
    "\n",
    "        job_status = await inspect_job(solver, job)\n",
    "        assert job_status.progress is not None # nosec\n",
    "        pbar.update(job_status.progress)\n",
    "        current_progress = job_status.progress\n",
    "        async for attempt in AsyncRetrying(wait=wait_fixed(1), retry=retry_if_exception_type()):\n",
    "            with attempt:\n",
    "                job_status = await inspect_job(solver, job)\n",
    "                assert job_status.progress is not None # nosec\n",
    "                if job_status.progress != current_progress:\n",
    "                    pbar.update(job_status.progress - current_progress)\n",
    "                    current_progress = job_status.progress\n",
    "                    \n",
    "                if not (job_status.progress == 100 and job_status.state in [\"FAILED\", \"SUCCESS\"]):\n",
    "                    raise TryAgain\n",
    "                \n",
    "        if job_status.state == \"FAILED\":\n",
    "            raise RuntimeError(\"job failed!\")\n",
    "        return job_status\n",
    "\n",
    "job_statuses = []\n",
    "with tqdm(total=len(jobs), desc=\"Running jobs\") as pbar:\n",
    "    for result in asyncio.as_completed([run_job(solver, job) for job in jobs]):\n",
    "        try:\n",
    "            job_statuses.append(await result)            \n",
    "        except osparc.ApiException as exc:\n",
    "            tqdm.write(f\"Error while running {job.id}: {exc}\")\n",
    "        finally:\n",
    "            pbar.update()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert all(status.state == \"SUCCESS\" for status in job_statuses)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get job submission timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(job_statuses[100])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get job result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await get_job_result(solver, jobs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jobs =await list_jobs(solver)\n",
    "delete_jobs(jobs)\n",
    "await asyncio.sleep(2)\n",
    "jobs =await list_jobs(solver)\n",
    "assert len(jobs) == 0, f\"found {len(jobs)} jobs\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
