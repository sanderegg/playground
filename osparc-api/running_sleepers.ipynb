{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_URL = \"https://api.osparc-master-zmt.click/\"\n",
    "API_KEY = \"testi_4311114729\"\n",
    "API_SECRET = \"9fe5517b639280a8a12e5dd076abee67de68a026\"\n",
    "SOLVER_NAME = \"simcore/services/comp/itis/sleeper\"\n",
    "SOLVER_VERSION = \"2.2.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OSPARC_DEV_FEATURES_ENABLED\"] = \"1\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# initialize connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing.pool import AsyncResult\n",
    "from tenacity import AsyncRetrying, TryAgain, retry_if_exception_type\n",
    "from tenacity.wait import wait_fixed\n",
    "from tqdm.auto import tqdm\n",
    "from rich import print\n",
    "import asyncio\n",
    "import functools\n",
    "import osparc\n",
    "import typing\n",
    "\n",
    "\n",
    "cfg = osparc.Configuration(\n",
    "    host=f\"{API_URL}\",\n",
    "    username=API_KEY,\n",
    "    password=API_SECRET,\n",
    ")\n",
    "# cfg.debug = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with osparc.ApiClient(cfg) as api_client:\n",
    "    profile = osparc.UsersApi(api_client).get_my_profile()\n",
    "    print(profile)\n",
    "    solvers_api = osparc.SolversApi(api_client)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = typing.cast(osparc.Solver, solvers_api.get_solver_release(SOLVER_NAME, SOLVER_VERSION))\n",
    "print(solver)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def create_job(solver: osparc.Solver) -> osparc.Job:\n",
    "    result = await asyncio.get_running_loop().run_in_executor(None, functools.partial(solvers_api.create_job,\n",
    "            solver.id,\n",
    "            solver.version,\n",
    "            osparc.JobInputs(\n",
    "                {\n",
    "                    \"input_2\": 300,\n",
    "                    \"input_4\": 0,\n",
    "                    \"input_5\": 0\n",
    "                }\n",
    "            ), async_req=True\n",
    "        ))\n",
    "    assert isinstance(result, AsyncResult) # nosec\n",
    "    # print(job)\n",
    "    return typing.cast(osparc.Job, await asyncio.get_running_loop().run_in_executor(None, result.get))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# list jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _list_jobs(solver: osparc.Solver) -> list[osparc.Job]:\n",
    "    assert solver.id\n",
    "    assert solver.version\n",
    "    gen = solvers_api.jobs(solver.id, solver.version)\n",
    "    return [job for job in gen if isinstance(job, osparc.Job)]\n",
    "\n",
    "\n",
    "async def list_jobs(solver: osparc.Solver) -> list[osparc.Job]:\n",
    "    return await asyncio.get_running_loop().run_in_executor(None, _list_jobs, solver)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inspect job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def inspect_job(solver: osparc.Solver, job: osparc.Job)-> osparc.JobStatus:\n",
    "    result = await asyncio.get_running_loop().run_in_executor(None, functools.partial(solvers_api.inspect_job, solver.id, solver.version, job.id,async_req=True))\n",
    "    assert isinstance(result, AsyncResult) # nosec\n",
    "    # print(status)\n",
    "    return typing.cast(osparc.JobStatus, await asyncio.get_running_loop().run_in_executor(None, result.get))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get job result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_job_result(solver: osparc.Solver, job: osparc.Job) -> osparc.JobOutputs:\n",
    "    result = await asyncio.get_running_loop().run_in_executor(None, functools.partial(solvers_api.get_job_outputs, solver.id, solver.version, job.id, async_req=True))\n",
    "    assert isinstance(result, AsyncResult) # nosecregistry.staging.osparc.io/simcore/services/comp/itis/sleeper:2.0.2\n",
    "    return typing.cast(osparc.JobOutputs, await asyncio.get_running_loop().run_in_executor(None, result.get))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# start job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def start_job(solver: osparc.Solver, job: osparc.Job) -> osparc.JobStatus:\n",
    "    result= await asyncio.get_running_loop().run_in_executor(None, functools.partial(solvers_api.start_job, solver.id, solver.version, job.id,async_req=True))\n",
    "    assert isinstance(result, AsyncResult) # nosec\n",
    "    return typing.cast(osparc.JobStatus, await asyncio.get_running_loop().run_in_executor(None, result.get))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stop job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def stop_job(solver: osparc.Solver, job: osparc.Job) -> osparc.Job:\n",
    "    result= await asyncio.get_running_loop().run_in_executor(None, functools.partial(solvers_api.stop_job, solver.id, solver.version, job.id,async_req=True))\n",
    "    assert isinstance(result, AsyncResult) # nosec\n",
    "    return typing.cast(osparc.Job, await asyncio.get_running_loop().run_in_executor(None, result.get))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# set job metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "async def set_job_metadata(solver: osparc.Solver, job: osparc.Job, job_metadata: dict[str, Any]) -> dict[str, Any]:\n",
    "    result= await asyncio.get_running_loop().run_in_executor(None, functools.partial(solvers_api.replace_job_custom_metadata, solver.id, solver.version, job.id, {\"metadata\":job_metadata},async_req=True))\n",
    "    assert isinstance(result, AsyncResult) # nosec\n",
    "    return typing.cast(dict[str, Any], await asyncio.get_running_loop().run_in_executor(None, result.get))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# delete job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def delete_job(solver: osparc.Solver, job: osparc.Job) -> None:\n",
    "    result = await asyncio.get_running_loop().run_in_executor(None, functools.partial(solvers_api.delete_job, solver.id, solver.version, job.id, async_req=True))\n",
    "    assert isinstance(result, AsyncResult) # nosec\n",
    "    await asyncio.get_running_loop().run_in_executor(None, result.get)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run N sleepers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_JOBS = 500\n",
    "\n",
    "created_jobs = []\n",
    "with tqdm(total=NUM_JOBS, desc=\"Creating jobs\") as pbar:\n",
    "    for result in asyncio.as_completed([create_job(solver) for _ in range(NUM_JOBS)]):\n",
    "        job = await result\n",
    "        created_jobs.append(job)\n",
    "        pbar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARENT_NODE_ID = \"7a7d6b38-7e9f-46b2-8cfb-4ee7ae20d0b1\"\n",
    "with tqdm(total=NUM_JOBS, desc=\"Setting jobs metadata\") as pbar:\n",
    "    for result in asyncio.as_completed([set_job_metadata(solver, job, job_metadata={\"job_index\": created_jobs.index(job), \"node_id\": PARENT_NODE_ID}) for job in created_jobs]):\n",
    "        await result\n",
    "        pbar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "async def run_job_wo_progressbar(solver: osparc.Solver, job: osparc.Job, status_dict: dict) -> osparc.JobStatus:\n",
    "    await start_job(solver, job)\n",
    "    job_status = await inspect_job(solver, job)\n",
    "    status_dict[job.id] = job_status.state\n",
    "    async for attempt in AsyncRetrying(wait=wait_fixed(1), retry=retry_if_exception_type()):\n",
    "        with attempt:\n",
    "            job_status = await inspect_job(solver, job)\n",
    "            status_dict[job.id] = job_status.state\n",
    "            if job_status.state not in [\"FAILED\", \"SUCCESS\", \"ABORTED\"]:\n",
    "                raise TryAgain\n",
    "    status_dict[job.id] = job_status.state\n",
    "    return job_status\n",
    "\n",
    "job_statuses = []\n",
    "status_dict = {}  # job_id -> state\n",
    "tasks = [asyncio.create_task(run_job_wo_progressbar(solver, job, status_dict)) for job in created_jobs]\n",
    "summary_interval = 5  # seconds\n",
    "done_count = 0\n",
    "with tqdm(total=len(created_jobs), desc=\"Running jobs\") as pbar:\n",
    "    while done_count < len(tasks):\n",
    "        done_count = sum(t.done() for t in tasks)\n",
    "        # Summarize states\n",
    "        states = Counter(status_dict.values())\n",
    "        pbar.n = done_count\n",
    "        pbar.refresh()\n",
    "        # Print summary every interval\n",
    "        if states:\n",
    "            tqdm.write(f\"Summary: {dict(states)}\", end=\"\\r\")\n",
    "        await asyncio.sleep(summary_interval)\n",
    "        \n",
    "    # Gather results\n",
    "    for t in tasks:\n",
    "        try:\n",
    "            job_statuses.append(await t)\n",
    "        except osparc.ApiException as exc:\n",
    "            tqdm.write(f\"Error while running job: {exc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_job(solver: osparc.Solver, job: osparc.Job) -> osparc.JobStatus:\n",
    "    job_prefix = f\"{solver.id}:{solver.version}-{job.id}\"\n",
    "    with tqdm(total=100, desc=job_prefix) as pbar:\n",
    "        await start_job(solver, job)\n",
    "\n",
    "        job_status = await inspect_job(solver, job)\n",
    "        assert job_status.progress is not None  # nosec\n",
    "        pbar.update(job_status.progress)\n",
    "        pbar.set_description_str(f\"{job_prefix}-----{job_status.state}\", refresh=True)\n",
    "        current_progress = job_status.progress\n",
    "        current_state = job_status.state\n",
    "        async for attempt in AsyncRetrying(\n",
    "            wait=wait_fixed(1), retry=retry_if_exception_type()\n",
    "        ):\n",
    "            with attempt:\n",
    "                job_status = await inspect_job(solver, job)\n",
    "                assert job_status.progress is not None  # nosec\n",
    "                if job_status.progress != current_progress:\n",
    "                    pbar.update(job_status.progress - current_progress)\n",
    "                    current_progress = job_status.progress\n",
    "\n",
    "                if current_state != job_status.state:\n",
    "                    pbar.set_description_str(\n",
    "                        f\"{job_prefix}-----{job_status.state}\", refresh=True\n",
    "                    )\n",
    "\n",
    "                if job_status.state not in [\"FAILED\", \"SUCCESS\", \"ABORTED\"]:\n",
    "                    raise TryAgain\n",
    "        return job_status\n",
    "\n",
    "\n",
    "job_statuses = []\n",
    "with tqdm(total=len(created_jobs), desc=\"Running jobs\") as pbar:\n",
    "    for result in asyncio.as_completed([run_job(solver, job) for job in created_jobs]):\n",
    "        try:\n",
    "            job_statuses.append(await result)\n",
    "        except osparc.ApiException as exc:\n",
    "            tqdm.write(f\"Error while running {job.id}: {exc}\")\n",
    "        finally:\n",
    "            pbar.update()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_inspection_results = await asyncio.gather( *(inspect_job(solver, job)for job in created_jobs))\n",
    "assert all(status.state == \"SUCCESS\" for status in job_inspection_results), job_inspection_results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get job result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(await get_job_result(solver, created_jobs[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleanup jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listed_jobs =await list_jobs(solver)\n",
    "from tqdm.asyncio import tqdm_asyncio\n",
    "await tqdm_asyncio.gather(*(stop_job(solver, job) for job in listed_jobs), desc=\"stopping jobs\")\n",
    "await tqdm_asyncio.gather(*(delete_job(solver, job) for job in listed_jobs), desc=\"deleting jobs\")\n",
    "await asyncio.sleep(3)\n",
    "listed_jobs =await list_jobs(solver)\n",
    "assert len(listed_jobs) == 0, f\"found {len(listed_jobs)} jobs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listed_jobs =await list_jobs(solver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "created_jobs = listed_jobs\n",
    "len(listed_jobs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproduce issue with multiple jobs sent at interval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### send first set of jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8 jobs first\n",
    "NUM_JOBS = 8\n",
    "jobs_1st_wave = []\n",
    "for i in tqdm(range(NUM_JOBS), desc=f\"Create and start {NUM_JOBS} jobs\"):\n",
    "    created_job = await create_job(solver)\n",
    "    jobs_1st_wave.append(created_job)\n",
    "    started_job = await start_job(solver, created_job)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8 jobs again\n",
    "NUM_JOBS = 8\n",
    "jobs_2nd_wave = []\n",
    "for i in tqdm(range(NUM_JOBS), desc=f\"Create and start {NUM_JOBS} jobs\"):\n",
    "    created_job = await create_job(solver)\n",
    "    jobs_2nd_wave.append(created_job)\n",
    "    started_job = await start_job(solver, created_job)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from osparc import Job, JobStatus, Solver\n",
    "\n",
    "\n",
    "async def check_job(solver: Solver, job: Job) -> JobStatus:\n",
    "    job_status = await inspect_job(solver, job)\n",
    "    assert job_status.progress is not None # nosec\n",
    "    last_progress = job_status.progress\n",
    "    with tqdm(total=100, desc=job_status.state) as pbar:\n",
    "        async for attempt in AsyncRetrying(wait=wait_fixed(1), retry=retry_if_exception_type()):\n",
    "            with attempt:\n",
    "                job_status = await inspect_job(solver, job)\n",
    "                assert job_status.progress is not None # nosec\n",
    "                if job_status.progress != last_progress:\n",
    "                    pbar.update(job_status.progress - last_progress)\n",
    "                if job_status.state != pbar.desc:\n",
    "                    pbar.set_description_str(job_status.state, refresh=True)\n",
    "                    last_progress = job_status.progress\n",
    "                    \n",
    "                if not job_status.state in [\"FAILED\", \"SUCCESS\"]:\n",
    "                    raise TryAgain\n",
    "        return job_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_statuses = []\n",
    "all_jobs = jobs_1st_wave + jobs_2nd_wave\n",
    "with tqdm(total=len(all_jobs), desc=\"Running jobs\") as pbar:\n",
    "    for result in asyncio.as_completed([check_job(solver, job) for job in all_jobs]):\n",
    "        try:\n",
    "            job_statuses.append(await result)            \n",
    "        except osparc.ApiException as exc:\n",
    "            tqdm.write(f\"Error while running {job.id}: {exc}\")\n",
    "        finally:\n",
    "            pbar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleanup\n",
    "all_jobs = await list_jobs(solver)\n",
    "from tqdm.asyncio import tqdm_asyncio\n",
    "await tqdm_asyncio.gather(*(stop_job(solver, job) for job in listed_jobs), desc=\"stopping jobs\")\n",
    "await tqdm_asyncio.gather(*(delete_job(solver, job) for job in all_jobs))\n",
    "all_jobs = await list_jobs(solver)\n",
    "assert len(all_jobs) == 0, f\"found {len(all_jobs)} jobs\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
